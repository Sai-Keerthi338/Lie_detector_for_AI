{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTcrRDTC5dAh/5W9FExSBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-Keerthi338/Lie_detector_for_AI/blob/main/Lie_detection_core_logic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries after installing libraries locally\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import faiss\n",
        "import pdfplumber\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Load embedding model\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# File paths for storage\n",
        "embeddings_file = \"trusted_embeddings.pt\"\n",
        "texts_file = \"trusted_chunks.pt\"\n",
        "\n",
        "# Load previous embeddings if they exist\n",
        "if os.path.exists(embeddings_file) and os.path.exists(texts_file):\n",
        "    trusted_embeddings = torch.load(embeddings_file)\n",
        "    trusted_chunks = torch.load(texts_file)\n",
        "else:\n",
        "    trusted_embeddings = torch.tensor([])\n",
        "    trusted_chunks = []\n",
        "\n",
        "# Build FAISS index (after embeddings are loaded)\n",
        "def build_faiss_index():\n",
        "    global index\n",
        "    if trusted_embeddings.nelement() == 0:\n",
        "        index = None\n",
        "        print(\" No embeddings to index.\")\n",
        "        return\n",
        "    dim = trusted_embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(trusted_embeddings.cpu().numpy())\n",
        "    print(f\" FAISS index built with {len(trusted_chunks)} chunks.\")\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Chunk text into ~100-word blocks\n",
        "def chunk_text(text, max_words=100):\n",
        "    sentences = re.split(r'\\. |\\n', text)\n",
        "    chunks, chunk = [], []\n",
        "    for s in sentences:\n",
        "        if len(\" \".join(chunk).split()) + len(s.split()) <= max_words:\n",
        "            chunk.append(s)\n",
        "        else:\n",
        "            chunks.append(\" \".join(chunk))\n",
        "            chunk = [s]\n",
        "    if chunk:\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "# Add a new trusted PDF to the system\n",
        "def add_pdf_to_index(pdf_path):\n",
        "    global trusted_chunks, trusted_embeddings\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    new_chunks = chunk_text(text)\n",
        "    existing_set = set(c.strip().lower() for c in trusted_chunks)\n",
        "    new_chunks = [c for c in new_chunks if c.strip().lower() not in existing_set]\n",
        "\n",
        "    if new_chunks:\n",
        "        new_embeddings = embed_model.encode(new_chunks, convert_to_tensor=True)\n",
        "        if trusted_embeddings.nelement() == 0:\n",
        "            trusted_embeddings = new_embeddings\n",
        "        else:\n",
        "            trusted_embeddings = torch.cat((trusted_embeddings, new_embeddings), dim=0)\n",
        "        trusted_chunks.extend(new_chunks)\n",
        "\n",
        "        # Save updated data\n",
        "        torch.save(trusted_embeddings, embeddings_file)\n",
        "        torch.save(trusted_chunks, texts_file)\n",
        "\n",
        "        build_faiss_index()\n",
        "        print(f\" Added {len(new_chunks)} new chunks from {pdf_path}\")\n",
        "    else:\n",
        "        print(\" No new chunks to add.\")\n",
        "\n",
        "#  Check similarity and flag hallucination\n",
        "def similarity_score(answer, k=1):\n",
        "    if index is None:\n",
        "        print(\" Index not built.\")\n",
        "        return 0\n",
        "    answer_emb = embed_model.encode(answer)\n",
        "    D, _ = index.search(np.array([answer_emb]), k)\n",
        "    score = 1 - D[0][0] / 2  # Convert L2 distance to similarity\n",
        "    print(f\" Similarity Score: {score:.3f}\")\n",
        "    return score\n",
        "\n",
        "def detect_by_similarity(answer, threshold=0.6):\n",
        "    sim = similarity_score(answer)\n",
        "    return sim < threshold  # True means it's likely a hallucination\n",
        "\n",
        "#  Test an AI answer\n",
        "def test_answer(answer):\n",
        "    print(f\"\\n AI Answer: {answer}\")\n",
        "    if detect_by_similarity(answer):\n",
        "        print(\" Flag: This might be a hallucination.\")\n",
        "    else:\n",
        "        print(\" Passed: Looks trustworthy.\")\n",
        "#add trusted files\n",
        "add_pdf_to_index(\"file_path\")\n",
        "#give ai answer as input\n",
        "test_answer(\"ai_answer\")\n"
      ],
      "metadata": {
        "id": "k3-ibeRV0zzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}